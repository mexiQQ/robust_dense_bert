Namespace(adam_epsilon=1e-08, bias_correction=True, bsz=32, ckpt_dir=PosixPath('tmp'), dataset_name='glue', debug=False, do_lower_case=True, epochs=5, eval_size=32, force_overwrite='1', lr=2e-05, max_seq_length=128, model_name='/hdd1/jianwei/workspace/OBC/bert/outputs_2x', num_examples=872, num_labels=2, result_file='attack_result.csv', seed=42, task_name='sst2', warmup_ratio=0.1, weight_decay=0.01)
Making checkpoint directory: tmp/finetune_glue-sst2_lr2e-05_epochs5_seed42_time1682630296886
> /hdd1/jianwei/workspace/robust_ticket_soups/dense/finetune_sparse_tickets.py(283)main()
-> print_model_sparsity(model)
(Pdb) 
Namespace(adam_epsilon=1e-08, bias_correction=True, bsz=32, ckpt_dir=PosixPath('tmp'), dataset_name='glue', debug=False, do_lower_case=True, epochs=5, eval_size=32, force_overwrite='1', lr=2e-05, max_seq_length=128, model_name='/hdd1/jianwei/workspace/OBC/bert/outputs_2x', num_examples=872, num_labels=2, result_file='attack_result.csv', seed=42, task_name='sst2', warmup_ratio=0.1, weight_decay=0.01)
Making checkpoint directory: tmp/finetune_glue-sst2_lr2e-05_epochs5_seed42_time1682642736786
bert.encoder.layer.0.attention.self.query 0.4982062445746528
bert.encoder.layer.0.attention.self.key 0.49762471516927087
bert.encoder.layer.0.attention.self.value 0.49766031901041663
bert.encoder.layer.0.attention.output.dense 0.49785868326822913
bert.encoder.layer.0.intermediate.dense 0.4976874457465278
bert.encoder.layer.0.output.dense 0.4995689392089844
bert.encoder.layer.1.attention.self.query 0.4978502061631944
bert.encoder.layer.1.attention.self.key 0.4975416395399306
bert.encoder.layer.1.attention.self.value 0.4976433648003472
bert.encoder.layer.1.attention.output.dense 0.49822998046875
bert.encoder.layer.1.intermediate.dense 0.49771923489040804
bert.encoder.layer.1.output.dense 0.4995223151312934
bert.encoder.layer.2.attention.self.query 0.4977179633246528
bert.encoder.layer.2.attention.self.key 0.4974280463324653
bert.encoder.layer.2.attention.self.value 0.49766201443142366
bert.encoder.layer.2.attention.output.dense 0.49822998046875
bert.encoder.layer.2.intermediate.dense 0.4976586235894097
bert.encoder.layer.2.output.dense 0.49951765272352433
bert.encoder.layer.3.attention.self.query 0.497711181640625
bert.encoder.layer.3.attention.self.key 0.4974450005425347
bert.encoder.layer.3.attention.self.value 0.4976433648003472
bert.encoder.layer.3.attention.output.dense 0.4981842041015625
bert.encoder.layer.3.intermediate.dense 0.4978218078613281
bert.encoder.layer.3.output.dense 0.4995274013943143
bert.encoder.layer.4.attention.self.query 0.49785190158420134
bert.encoder.layer.4.attention.self.key 0.4974450005425347
bert.encoder.layer.4.attention.self.value 0.49762471516927087
bert.encoder.layer.4.attention.output.dense 0.4981842041015625
bert.encoder.layer.4.intermediate.dense 0.49784766303168404
bert.encoder.layer.4.output.dense 0.49949052598741317
bert.encoder.layer.5.attention.self.query 0.4977484809027778
bert.encoder.layer.5.attention.self.key 0.4974653455946181
bert.encoder.layer.5.attention.self.value 0.4976111518012153
bert.encoder.layer.5.attention.output.dense 0.498199462890625
bert.encoder.layer.5.intermediate.dense 0.4979557461208768
bert.encoder.layer.5.output.dense 0.49949730767144096
bert.encoder.layer.6.attention.self.query 0.49776882595486116
bert.encoder.layer.6.attention.self.key 0.49748738606770837
bert.encoder.layer.6.attention.self.value 0.49764506022135413
bert.encoder.layer.6.attention.output.dense 0.4981909857855903
bert.encoder.layer.6.intermediate.dense 0.4980553521050347
bert.encoder.layer.6.output.dense 0.49954138861762154
bert.encoder.layer.7.attention.self.query 0.49782307942708337
bert.encoder.layer.7.attention.self.key 0.49753994411892366
bert.encoder.layer.7.attention.self.value 0.4976179334852431
bert.encoder.layer.7.attention.output.dense 0.49812655978732634
bert.encoder.layer.7.intermediate.dense 0.4980625576443143
bert.encoder.layer.7.output.dense 0.4995337592230903
bert.encoder.layer.8.attention.self.query 0.4979841444227431
bert.encoder.layer.8.attention.self.key 0.4976213243272569
bert.encoder.layer.8.attention.self.value 0.4975823296440972
bert.encoder.layer.8.attention.output.dense 0.4982079399956597
bert.encoder.layer.8.intermediate.dense 0.49812020195855033
bert.encoder.layer.8.output.dense 0.4995447794596354
bert.encoder.layer.9.attention.self.query 0.49799770779079866
bert.encoder.layer.9.attention.self.key 0.49767727322048616
bert.encoder.layer.9.attention.self.value 0.4976281060112847
bert.encoder.layer.9.attention.output.dense 0.49807230631510413
bert.encoder.layer.9.intermediate.dense 0.4979379442003038
bert.encoder.layer.9.output.dense 0.49953291151258683
bert.encoder.layer.10.attention.self.query 0.4981757269965278
bert.encoder.layer.10.attention.self.key 0.498046875
bert.encoder.layer.10.attention.self.value 0.49753824869791663
bert.encoder.layer.10.attention.output.dense 0.49809773763020837
bert.encoder.layer.10.intermediate.dense 0.4982015821668837
bert.encoder.layer.10.output.dense 0.49952612982855904
bert.encoder.layer.11.attention.self.query 0.4983079698350694
bert.encoder.layer.11.attention.self.key 0.4976569281684028
bert.encoder.layer.11.attention.self.value 0.49761962890625
bert.encoder.layer.11.attention.output.dense 0.49821133083767366
bert.encoder.layer.11.intermediate.dense 0.49783409966362846
bert.encoder.layer.11.output.dense 0.4994591606987847
bert.pooler.dense 0.0
classifier 0.0
Epoch: 0, Loss:  0.0449, Lr:  1.778e-05, Dev_Accuracy: 0.9071100917431192
**** Test Accuracy: 0.9071100917431192, Test_Loss: 0.4440433147496395
Epoch: 1, Loss:  0.0212, Lr:  1.333e-05, Dev_Accuracy: 0.9071100917431192
Epoch: 2, Loss:  0.0118, Lr:  8.886e-06, Dev_Accuracy: 0.9059633027522934
Epoch: 3, Loss:  0.0077, Lr:  4.441e-06, Dev_Accuracy: 0.9071100917431192
Epoch: 4, Loss:  0.0050, Lr:  0.000e+00, Dev_Accuracy: 0.9116972477064219
**** Test Accuracy: 0.9116972477064219, Test_Loss: 0.6452508191744375
**** Best dev metric: 0.9116972477064219 in Epoch: 4
**** Best Test metric: 0.9116972477064219 in Epoch: 4
Last epoch test_accuracy: 0.9116972477064219, test_loss: 0.6452508191744375
Spend time: 0.23694444444444446
